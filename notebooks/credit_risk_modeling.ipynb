{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0727254e",
   "metadata": {},
   "source": [
    "# Credit Risk Modeling\n",
    "This notebook explores credit risk data and trains a machine learning model for credit risk assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e017a",
   "metadata": {},
   "source": [
    "## Configuration and Imports\n",
    "Setting up necessary libraries and configurations for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae633ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard data manipulation and visualization libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning components\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "# Custom modules\n",
    "from src.model_training import (\n",
    "    load_data,\n",
    "    build_full_pipeline,\n",
    "    train_model,\n",
    "    evaluate_model,\n",
    "    save_pipeline\n",
    ")\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb96f57",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "Loading the credit risk dataset from the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad555158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = load_data('data/generated_credit_data.csv')\n",
    "print(\"Dataset shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df4c436",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "Analyzing the structure and characteristics of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f4282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data exploration\n",
    "print(\"Data Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Check missing values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data.isnull(), yticklabels=False, cbar=True, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "data['default'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.xlabel('Default Status')\n",
    "plt.ylabel('Proportion')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2809010d",
   "metadata": {},
   "source": [
    "## Preprocessing and Feature Engineering\n",
    "Preparing the data for model training by splitting into train/test sets and applying the preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = data.drop('default', axis=1)\n",
    "y = data['default']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Build and fit the pipeline\n",
    "pipeline = build_full_pipeline()\n",
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "print(\"Transformed training data shape:\", X_train_transformed.shape)\n",
    "print(\"Transformed test data shape:\", X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbcc74c",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Training the model using GridSearchCV for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model, best_params, best_score = train_model(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Validation ROC AUC Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020849bf",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluating the model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc437355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "metrics = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "print(\"Test Set Metrics:\")\n",
    "print(f\"ROC AUC: {metrics['roc_auc']:.3f}\")\n",
    "print(f\"Precision: {metrics['precision']:.3f}\")\n",
    "print(f\"Recall: {metrics['recall']:.3f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(metrics['confusion_matrix'], annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(metrics['fpr'], metrics['tpr'])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18645e5e",
   "metadata": {},
   "source": [
    "## Pipeline Saving\n",
    "Saving the trained pipeline for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pipeline\n",
    "save_pipeline(pipeline, 'models/credit_risk_pipeline.pkl')\n",
    "print(\"Pipeline saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
